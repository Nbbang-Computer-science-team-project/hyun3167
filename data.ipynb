{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "import imageio\n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os \n",
    "import json\n",
    "import matplotlib.pylab as plt\n",
    "from PIL import Image\n",
    "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
    "from os import listdir\n",
    "from glob import glob\n",
    "\n",
    "p = os.getcwd() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#회전\n",
    "def rotation(img_path,txt_path, image, label):\n",
    "    ia.seed(1)\n",
    "    with open(label) as f:\n",
    "        json_data = json.load(f)\n",
    "    image = imageio.imread(image)\n",
    "    # file_name = json_data['description']['image'].split('.')[0]\n",
    "    \n",
    "    xtl = json_data['annotations']['points'][0]['xtl']\n",
    "    ytl = json_data['annotations']['points'][0]['ytl']\n",
    "    xbr = json_data['annotations']['points'][0]['xbr']\n",
    "    ybr = json_data['annotations']['points'][0]['ybr']\n",
    "    w = json_data['description']['width']\n",
    "    h = json_data['description']['height']\n",
    "    \n",
    "    area = json_data['annotations']['area']\n",
    "    name = json_data['annotations']['disease']\n",
    "    risk = json_data['annotations']['risk']\n",
    "    grow = json_data['annotations']['grow']\n",
    "\n",
    "    if name == 0:\n",
    "        if grow == 11:\n",
    "            c = 0\n",
    "        else:\n",
    "            c = 1\n",
    "    elif name == 5:\n",
    "        c = risk + 1\n",
    "    elif name == 6:\n",
    "        c = 4 + risk\n",
    "\n",
    "    bf = []\n",
    "    bf.append([int(xtl), int(ytl), int(xbr), int(ybr)])\n",
    "    ia_bf = []\n",
    "    for box in bf:\n",
    "        ia_bf.append(ia.BoundingBox(x1=box[0],y1=box[1],x2=box[2],y2=box[3],label = c))\n",
    "        \n",
    "    bbs = ia.BoundingBoxesOnImage(ia_bf, shape = image.shape)\n",
    "    name2 = label.split('\\\\')[-1]\n",
    "    name_re = name2.split('.')[0]\n",
    "    print('c = '+str(c))\n",
    "    for j in range(1, 4):\n",
    "        rtt = 90*j\n",
    "        seq = iaa.Sequential([\n",
    "            iaa.Affine(rotate=rtt)\n",
    "        ])\n",
    "        img_aug, bbs_aug = seq(image = image,bounding_boxes = bbs)\n",
    "        \n",
    "        x1 = bbs_aug.bounding_boxes[0].x1\n",
    "        y1 = bbs_aug.bounding_boxes[0].y1\n",
    "        x2 = bbs_aug.bounding_boxes[0].x2\n",
    "        y2 = bbs_aug.bounding_boxes[0].y2\n",
    "            \n",
    "        w = bbs_aug.shape[1]\n",
    "        h = bbs_aug.shape[0]\n",
    "        # print(name2)\n",
    "        # print(bbs_aug)\n",
    "        # print(j)\n",
    "        if x1 < 0:\n",
    "            x1 = 0\n",
    "        else : pass\n",
    "        if y1 < 0:\n",
    "            y1 = 0\n",
    "        else : pass\n",
    "        if x2 < 0:\n",
    "            x2 = 0\n",
    "        else : pass\n",
    "        if y2 < 0:\n",
    "            y2 = 0  \n",
    "        else : pass\n",
    "        x_center = (x1 + (x2-x1)/2)/w\n",
    "        y_center = (y1 + (y2-y1)/2)/h\n",
    "        x = (x2-x1)/w\n",
    "        y = (y2-y1)/h\n",
    "        # # image_after = bbs_aug.draw_on_image(img_aug, thickness=10, color = [0, 0, 255])\n",
    "        cv2.imwrite(img_path+str(j)+'-'+name_re+'.jpg',img_aug)\n",
    "        fw = open(txt_path+str(j)+'-'+name_re+\".txt\", 'w')\n",
    "        fw.write(str(c)+' '+str(x_center)+' '+str(y_center)+' '+str(x)+' '+str(y))\n",
    "        f.close()\n",
    "            \n",
    "        # # cv2_imshow(cv2.resize(image_after, (w,h)))\n",
    "        print('c = '+str(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#json -> yolo txt\n",
    "def convert(path, label):\n",
    "    with open(label) as f:\n",
    "        json_data = json.load(f)\n",
    "    if json_data['annotations']['area'] == 3:\n",
    "        file_name = json_data['description']['image'].split('.')[0]\n",
    "        xtl = json_data['annotations']['points'][0]['xtl']\n",
    "        ytl = json_data['annotations']['points'][0]['ytl']\n",
    "        xbr = json_data['annotations']['points'][0]['xbr']\n",
    "        ybr = json_data['annotations']['points'][0]['ybr']\n",
    "\n",
    "        w = json_data['description']['width']\n",
    "        h = json_data['description']['height']\n",
    "\n",
    "        x_center = (xtl + (xbr-xtl)/2)/w\n",
    "        y_center = (ytl + (ybr-ytl)/2)/h\n",
    "        x = (xbr-xtl)/w\n",
    "        y = (ybr-ytl)/h\n",
    "\n",
    "        area = json_data['annotations']['area']\n",
    "        name = json_data['annotations']['disease']\n",
    "        risk = json_data['annotations']['risk']\n",
    "        grow = json_data['annotations']['grow']\n",
    "\n",
    "\n",
    "        if name == 0:\n",
    "            if grow == 11:\n",
    "                c = 0\n",
    "            else:\n",
    "                c = 1\n",
    "        elif name == 5:\n",
    "            c = risk + 1\n",
    "        elif name == 6:\n",
    "            c = 4 + risk\n",
    "        fw = open(path+file_name+\".txt\", 'w')\n",
    "        fw.write(str(c)+' '+str(x_center)+' '+str(y_center)+' '+str(x)+' '+str(y)+'\\n')\n",
    "        f.close()\n",
    "        # print(file_name)\n",
    "    else:\n",
    "        os.remove(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#분포\n",
    "def distribution(label,lst):\n",
    "    with open(label,'r') as f:\n",
    "        read = f.read(1)\n",
    "        lst.append(read)\n",
    "    return lst\n",
    "\n",
    "def distribution2(lst,dic):\n",
    "    for i in lst:\n",
    "        try: dic[i] += 1\n",
    "        except: dic[i] = 1\n",
    "    fa = sorted(dic.items())\n",
    "    return fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#그래프 표시\n",
    "def grape(x,y):\n",
    "    plt.bar(x,y)\n",
    "    for k, v in enumerate(x):\n",
    "        plt.text(v, y[k], y[k],                 \n",
    "             fontsize = 9, \n",
    "             color='red',\n",
    "             horizontalalignment='center',  \n",
    "             verticalalignment='bottom')    # verticalalignment (top, center, bottom)\n",
    "    plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 지우기\n",
    "def Data_remove(img, txt, dic, cnt):\n",
    "    i = 0\n",
    "    for file in txt:\n",
    "        with open(txt[i],'r') as f:\n",
    "            read = f.read(1)\n",
    "        if dic[read] == int(cnt):\n",
    "            i = i + 1\n",
    "            pass\n",
    "        else:\n",
    "            print(read)\n",
    "            print(img[i])\n",
    "            print(txt[i])\n",
    "            os.remove(img[i])\n",
    "            os.remove(txt[i])\n",
    "            dic[read] = dic[read] - 1\n",
    "            print(dic)\n",
    "            i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#밝기\n",
    "def color_brightness(img_path, txt_path, name, img, label, value):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV) \n",
    "    h, s, v = cv2.split(hsv) \n",
    "    \n",
    "    lim = 255 - value \n",
    "    v[v > lim] = 255 \n",
    "    v[v <= lim] += value \n",
    "    \n",
    "    final_hsv = cv2.merge((h, s, v)) \n",
    "    img = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "\n",
    "    cv2.imwrite(img_path+'c'+name+'.jpg', img)\n",
    "\n",
    "    bf = open(label,'r')\n",
    "    af = open(txt_path+'c'+name+\".txt\", 'w')\n",
    "    bl = bf.readlines()\n",
    "    for inStr in bl:\n",
    "        af.writelines(inStr)\n",
    "    \n",
    "    bf.close()\n",
    "    af.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#블러\n",
    "def blurs(img_path, txt_path, name, img, label):\n",
    "    blur1 = cv2.GaussianBlur(img,(5,5),0)\n",
    "    cv2.imwrite(img_path+'g'+name+'.jpg', blur1)\n",
    "\n",
    "    bf = open(label,'r')\n",
    "    af = open(txt_path+'g'+name+\".txt\", 'w')\n",
    "    bl = bf.readlines()\n",
    "    for inStr in bl:\n",
    "        af.writelines(inStr)\n",
    "    \n",
    "    bf.close()\n",
    "    af.close()\n",
    "    \n",
    "    blur2 = cv2.medianBlur(img,5)\n",
    "    cv2.imwrite(img_path+'m'+name+'.jpg', blur2)\n",
    "\n",
    "    bf = open(label,'r')\n",
    "    af = open(txt_path+'m'+name+\".txt\", 'w')\n",
    "    bl = bf.readlines()\n",
    "    for inStr in bl:\n",
    "        af.writelines(inStr)\n",
    "    \n",
    "    bf.close()\n",
    "    af.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 40\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "t = os.getcwd() +'\\datasets\\\\train\\\\labels\\\\'\n",
    "v = os.getcwd() +'\\datasets\\\\valid\\\\labels\\\\'\n",
    "train_label_json = glob(p + '\\\\label\\\\label-t\\\\*')\n",
    "valid_label_json = glob(p + '\\\\label\\\\label-v\\\\*')\n",
    "for i in range(len(train_label_json)):\n",
    "    convert(t,train_label_json[i])\n",
    "\n",
    "for i in range(len(valid_label_json)):\n",
    "    convert(v,valid_label_json[i])\n",
    "    \n",
    "train_label_txt = glob(p+'/datasets/train/labels/*')\n",
    "valid_label_txt = glob(p+'/datasets/valid/labels/*')\n",
    "print(len(train_label_txt), len(valid_label_txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 40 800 40 800 40\n"
     ]
    }
   ],
   "source": [
    "#데이터 / 데이터 정렬\n",
    "t = os.getcwd() +'\\datasets\\\\train\\\\labels\\\\'\n",
    "v = os.getcwd() +'\\datasets\\\\valid\\\\labels\\\\'\n",
    "train_label_json = glob(p + '\\\\label\\\\label-t\\\\*')\n",
    "valid_label_json = glob(p + '\\\\label\\\\label-v\\\\*')\n",
    "train_label_txt = glob(p+'\\\\datasets\\\\train\\\\labels\\\\*')\n",
    "valid_label_txt = glob(p+'\\\\datasets\\\\valid\\\\labels\\\\*')\n",
    "train_img = glob(p+'\\\\datasets\\\\train\\\\images\\\\*')\n",
    "valid_img = glob(p+'\\\\datasets\\\\valid\\\\images\\\\*')\n",
    "\n",
    "train_img.sort()\n",
    "valid_img.sort()\n",
    "train_label_json.sort()\n",
    "valid_label_json.sort()\n",
    "train_label_txt.sort()\n",
    "valid_label_txt.sort()\n",
    "\n",
    "print(len(train_img),len(valid_img),len(train_label_json),len(valid_label_json),len(train_label_txt), len(valid_label_txt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400 120\n"
     ]
    }
   ],
   "source": [
    "img_train_path = glob('C:\\\\Users\\\\a\\\\Desktop\\\\swproject\\\\test\\\\train\\\\images\\\\*')\n",
    "txt_train_path = glob('C:\\\\Users\\\\a\\\\Desktop\\\\swproject\\\\test\\\\train\\\\labels\\\\*')\n",
    "\n",
    "\n",
    "img_valid_path = glob('C:\\\\Users\\\\a\\\\Desktop\\\\swproject\\\\test\\\\valid\\\\images\\\\*')\n",
    "txt_valid_path = glob('C:\\\\Users\\\\a\\\\Desktop\\\\swproject\\\\test\\\\valid\\\\labels\\\\*')\n",
    "\n",
    "print(len(img_train_path), len(img_valid_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path_t = 'C:\\\\Users\\\\a\\\\Desktop\\\\swproject\\\\test\\\\train\\\\images\\\\'\n",
    "txt_path_t = 'C:\\\\Users\\\\a\\\\Desktop\\\\swproject\\\\test\\\\train\\\\labels\\\\'\n",
    "\n",
    "img_path_v = 'C:\\\\Users\\\\a\\\\Desktop\\\\swproject\\\\test\\\\valid\\\\images\\\\'\n",
    "txt_path_v = 'C:\\\\Users\\\\a\\\\Desktop\\\\swproject\\\\test\\\\valid\\\\labels\\\\'\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(train_img)):\n",
    "    rotation(img_path_v, txt_path_v ,valid_img[i],valid_label_json[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_img)):\n",
    "    sp = train_img[i].split('\\\\')[-1]\n",
    "    name = sp.split('.')[0]\n",
    "    sample = cv2.imread(train_img[i])\n",
    "    color_brightness(img_path_t, txt_path_t, name, sample, train_label_txt[i], 50)\n",
    "\n",
    "for i in range(len(valid_img)):\n",
    "    sp = valid_img[i].split('\\\\')[-1]\n",
    "    name = sp.split('.')[0]\n",
    "    sample = cv2.imread(valid_img[i])\n",
    "    color_brightness(img_path_v, txt_path_v, name, sample, valid_label_txt[i], 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_img)):\n",
    "    sp = train_img[i].split('\\\\')[-1]\n",
    "    name = sp.split('.')[0]\n",
    "    sample = cv2.imread(train_img[i])\n",
    "    blurs(img_path_t, txt_path_t, name, sample, train_label_txt[i])\n",
    "\n",
    "for i in range(len(valid_img)):\n",
    "    sp = valid_img[i].split('\\\\')[-1]\n",
    "    name = sp.split('.')[0]\n",
    "    sample = cv2.imread(valid_img[i])\n",
    "    blurs(img_path_v, txt_path_v, name, sample, valid_label_txt[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = []\n",
    "d_train2 = {}\n",
    "\n",
    "for i in range(len(train_label_txt)):\n",
    "    distribution(train_label_txt[i],d_train)\n",
    "\n",
    "trainx, trainy = zip(*distribution2(d_train,d_train2))\n",
    "\n",
    "grape(trainx, trainy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_valid = []\n",
    "d_valid2 = {}\n",
    "\n",
    "for i in range(len(valid_label_txt)):\n",
    "    distribution(valid_label_txt[i],d_valid)\n",
    "\n",
    "validx, validy = zip(*distribution2(d_valid,d_valid2))\n",
    "\n",
    "grape(validx, validy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800\n"
     ]
    }
   ],
   "source": [
    "test = glob(p+'\\\\test\\\\train\\\\images\\\\*')\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_remove(train_label_json,train_label_txt,d_train2,100)\n",
    "Data_remove(valid_label_json,valid_label_txt,d_valid2,5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOV5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#git yolo / requirments\n",
    "p = os.getcwd() \n",
    "\n",
    "%cd $p\n",
    "!git clone https://github.com/ultralytics/yolov5\n",
    "\n",
    "%cd yolov5\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yaml edit\n",
    "import yaml\n",
    "\n",
    "with open(p+'/datasets/data.yaml','r') as f:\n",
    "    data = yaml.safe_load(f)\n",
    "\n",
    "data['train'] = p + '\\\\datasets\\\\train\\\\images\\\\'\n",
    "data['val'] = p + '\\\\datasets\\\\valid\\\\images\\\\'\n",
    "data['nc'] = 8\n",
    "data['names'] = ['normal','normal+', 'risk-1-1', 'risk-1-2', 'risk-1-3', 'risk-2-1', 'risk-2-2', 'risk-2-3']\n",
    "\n",
    "with open(p+'/datasets/data.yaml','w') as f:\n",
    "    yaml.dump(data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "#train yolo\n",
    "!python train.py --img 640 --batch 80 --epochs 300 --data $p/datasets/data.yaml --cfg ./models/yolov5s.yaml --weights yolov5s.pt --name s  --cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reinitialized existing Git repository in C:/Users/oo/Desktop/swproject/yolov5/.git/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Author identity unknown\n",
      "\n",
      "*** Please tell me who you are.\n",
      "\n",
      "Run\n",
      "\n",
      "  git config --global user.email \"you@example.com\"\n",
      "  git config --global user.name \"Your Name\"\n",
      "\n",
      "to set your account's default identity.\n",
      "Omit --global to set the identity only in this repository.\n",
      "\n",
      "fatal: unable to auto-detect email address (got 'oo@DESKTOP-GQ6JF6T.(none)')\n",
      "error: remote origin already exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: helper error (-1): User cancelled dialog.\n",
      "bash: /dev/tty: No such device or address\n",
      "error: failed to execute prompt script (exit code 1)\n",
      "fatal: could not read Username for 'https://github.com': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!echo \"# hyun3167\" >> README.md\n",
    "!git init\n",
    "!git add README.md\n",
    "!git commit -m \"first commit\"\n",
    "!git branch -M main\n",
    "!git remote add origin https://github.com/Nbbang-Computer-science-team-project/hyun3167.git\n",
    "!git push -u origin main"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c758575c4709e9d5f400e9d2c26e84f02edf8d830571b7d94b54173fc15bb0af"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('plz')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
